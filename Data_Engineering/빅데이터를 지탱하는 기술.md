# 빅데이터를 지탱하는 기술

## 빅데이터 기초 지식

빅데이터의 취급이 어려운 이유는 크게 두가지다. 하나는 '데이터의 분석 방법을 모른다'는 점이고, 또 하나의 이유는 '데이터 처리에 수고와 시간이 걸린다'는 점이다.
_Hadoop_ 은 '다수의 컴퓨터에서 대량의 데이터를 처리하기'위한 시스템이다.

가속도적으로 늘어나는 데이터의 처리는 Hadoop에 맡기고 비교적 작은 데이터, 또는 중요한 데이터만을 데이터 웨어하우스에 넣는 식으로 사용을 구분하게 되었다.
Amazon Redshift 이후로 데이터 웨어하우스를 클라우드 상에서 작성하는 것은 그다지 드문일이 아니게 되었다.

스몰데이터(한 대의 노트북에서 큰 부담없이 처리할 수 있을 만큼의 작은 데이터, 수 GB) 기술은 데이터양이 증가하면 처리 시간이 급격히 증가한다.
빅데이터의 경우 데이터의 양이 적은 상황에서는 스몰 데이터 기술이 더 우수하다.

## 2020.12.05

일반적으로 차례대로 전달해나가는 데이터로 구성된 시스템을 '__데이터 파이프라인__'이라고 한다.

빅데이터 기술이 기존의 데이터 웨어하우스와 다른 점은 다수의 분산 시스템을 조합하여 확장성이 뛰어난 데이터 처리 구조를 만든다는 점이다.

대량의 데이터를 수집한 후 분산처리하는 것이 좋다. 

분산 스토리지는 여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템을 말한다.

그 대표적인 것이 객체 스토리지이고, 유명한 서비스로는 Amazon S3가 있다.

데이터를 저장하였으면 분산 스토리지에서 추출한 데이터를 데이터 웨어하우스에 적합한 형식으로 변환한다. -> 이 작업이 ETL 프로세스

데이터 웨어하우스는 대량의 데이터를 장기보존하는데에 초점이 맞추어져 있다. (Amazon Redshift)  
(하루에 몇번씩 소량으로 꺼내어 자주 쓰기 보다는 하루가 끝날 때 정리하는 정도)

데이터 분석을 위한 데이터들은 (자주 사용하고, 과부화 걸리지 않게 하기 위해) 데이터 마트에 저장한다.

많은 데이터를 우선 저장하고 보는게 데이터 레이크이다. -> 단순 스토리지 (아직 데이터 웨어하우스에 넣을 수 없는 데이터)

항상 데이터가 먼저 있고, 테이블을 나중에 설계하는 것이 빅데이터

__데이터 파이프라인의 큰 흐름은 변하지 않는다.__  
+ 저장할 수 있는 데이터의 제한이 없을 것
+ 데이터를 효율적으로 추출할 수단이 있을 것

데이터 파이프라인 흐름: 데이터 수집 -> 분산 스토리지 -> 분산 데이터 처리 -> 데이터 마트 -> 시각화 도구

데이터 수집의 목적으로는 크게 3가지가 있다.

1. 데이터 검색: 만약 시스템에 장애가 발생하였을 때 원인을 찾거나 고객으로부터 문의가 있을 경우 로그 탐색하는 경우 등. 어떤것이 필요할지 모르기 때문에 모든 데이터를 취득

2. 데이터 가공: 추천 상품을 제안하거나 센서 데이터에서 비정상적인 상태를 감지해서 통보하는 경우 등등. 필요한 데이터를 사전에 모아 설계해둠. -> 데이터 가공에는 자동화가 필수

3. 데이터 시각화: 데이터를 시각적으로 봄으로써 얻고 싶은 정보가 있는 경우. 통계 SW나 BI 툴 활용해 의사결정에 도움. 

## 2020.12.08

스키마가 명확하게 정의된 데이터를 구조화된 데이터라고 한다. -> 데이터 웨어하우스의 데이터는 항상 구조화된 데이터로 축적하는 것이 일반적

하지만 빅데이터에는 스키마가 없는 비구조화 데이터가 있다. -> 이 상태로는 SQL로 집계할 수 없음.

따라서 이 비구조화 데이터를 분산 스토리지에 저장하고 분산 시스템에서 처리하는 것이 데이터 레이크의 개념! -> 데이터를 가공하는 과정에서 스키마를 정의하고 구조화된 데이터로 변환!

구조화된 데이터로 변경하기 위해 열 지향 스토리지로 저장한다. -> MPP 데이터베이스로 전송하거나 Hadoop 상에서 열 지향 스토리지 형식으로 변환 

MPP 데이터베이스: MPP (massive parallel processing : 대규모 병렬 처리) -> Amazon Redshift, Big Query

Hadoop : 분산 데이터 처리를 위한 공통 플랫폼  
-> 분산 파일 시스템이라고 불리는 __HDFS__ (Hadoop Distributed File System) + 리소스 관리자 __YARN__ (Yet Another Resource Negotiator) + 분산 데이터 처리 기반의 __Map Reduce__

하둡에서 처리되는 대부분의 데이터는 분산 파일 시스템인 HDFS에 저장되고, 계산 리소스는 YARN에 의해 관리된다.

SQL 등의 쿼리 언어에 의한 데이터 집계가 목적이라면 -> Apache Hive (쿼리 엔진)
